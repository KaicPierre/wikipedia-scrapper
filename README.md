# Wikipedia Scraper & Summarizer

API FastAPI para extrair e resumir artigos da Wikipedia usando IA (Ollama ou OpenAI).

## ğŸ“‹ Ãndice

- [CaracterÃ­sticas](#-caracterÃ­sticas)
- [Tecnologias](#-tecnologias)
- [PrÃ©-requisitos](#-prÃ©-requisitos)
- [InstalaÃ§Ã£o e ExecuÃ§Ã£o](#-instalaÃ§Ã£o-e-execuÃ§Ã£o)
  - [OpÃ§Ã£o 1: Rodando Localmente com UV](#opÃ§Ã£o-1-rodando-localmente-com-uv)
  - [OpÃ§Ã£o 2: Rodando com Docker Compose](#opÃ§Ã£o-2-rodando-com-docker-compose)
- [Uso da API](#-uso-da-api)
- [Testes](#-testes)
- [DecisÃµes de Projeto](#-decisÃµes-de-projeto)
- [Estrutura do Projeto](#-estrutura-do-projeto)

## âœ¨ CaracterÃ­sticas

- ExtraÃ§Ã£o automÃ¡tica de conteÃºdo de artigos da Wikipedia em portuguÃªs
- GeraÃ§Ã£o de resumos usando IA (Ollama ou OpenAI)
- Armazenamento de resumos no banco de dados PostgreSQL
- API REST com documentaÃ§Ã£o automÃ¡tica (Swagger)
- Testes unitÃ¡rios com 100% de cobertura nos services
- ContainerizaÃ§Ã£o completa com Docker Compose

## ğŸš€ Tecnologias

- **Python 3.12** - Linguagem principal
- **FastAPI** - Framework web
- **UV** - Gerenciador de pacotes e ambientes Python
- **SQLAlchemy** - ORM para banco de dados
- **PostgreSQL** - Banco de dados relacional
- **Ollama** - ExecuÃ§Ã£o local de modelos LLM
- **LangChain** - Framework para aplicaÃ§Ãµes com LLMs
- **BeautifulSoup4** - Web scraping
- **Docker & Docker Compose** - ContainerizaÃ§Ã£o

## ğŸ“¦ PrÃ©-requisitos

### Para execuÃ§Ã£o local:
- Python 3.12+
- UV (gerenciador de pacotes): `pip install uv`
- PostgreSQL 15+
- Ollama (opcional, para usar LLMs locais): [https://ollama.ai](https://ollama.ai)

### Para execuÃ§Ã£o com Docker:
- Docker 20.10+
- Docker Compose 2.0+

## ğŸ”§ InstalaÃ§Ã£o e ExecuÃ§Ã£o

### OpÃ§Ã£o 1: Rodando Localmente com UV

#### 1. Clone o repositÃ³rio
```bash
git clone https://github.com/KaicPierre/wikipedia-scrapper.git
cd wikipedia-scrapper
```

#### 2. Configure o arquivo .env
```bash
cp .env.example .env
```

Edite o `.env` com suas configuraÃ§Ãµes:
```env
# Database
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=wikipedia_db
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/wikipedia_db

# Model Configuration
MODEL=OLLAMA  # ou GPT para usar OpenAI

# OpenAI (opcional - necessÃ¡rio apenas se MODEL=GPT)
OPENAI_API_KEY=sua-chave-aqui

# Ollama (se estiver usando localmente)
OLLAMA_BASE_URL=http://localhost:11434
```

#### 3. Instale as dependÃªncias
```bash
uv sync
```

#### 4. Configure o PostgreSQL
Certifique-se de que o PostgreSQL estÃ¡ rodando e crie o banco de dados:
```bash
docker compose up db -d
```

#### 5. (Opcional) Configure o Ollama
Se vocÃª escolheu usar Ollama localmente adicione as envs:
```env
MODEL=OLLAMA
OPENAI_API_KEY=not-needed
```

**Instale o Ollama:**
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

**Baixe o modelo Mistral:**
```bash
ollama pull mistral
```

**Inicie o servidor Ollama (se nÃ£o iniciar automaticamente):**
```bash
ollama serve
```

#### 6. Execute a aplicaÃ§Ã£o
```bash
uv run python -m uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

A API estarÃ¡ disponÃ­vel em:
- **DocumentaÃ§Ã£o**: http://localhost:8000/docs
- **API**: http://localhost:8000

---

### OpÃ§Ã£o 2: Rodando com Docker Compose

#### 1. Clone o repositÃ³rio
```bash
git clone https://github.com/KaicPierre/wikipedia-scrapper.git
cd wikipedia-scrapper
```

#### 2. Configure o arquivo .env
```bash
cp .env.example .env
```

Para usar com **OpenAI** (recomendado com Docker):
```env
MODEL=GPT
OPENAI_API_KEY=sua-chave-openai
```

Para usar com **Ollama** (âš ï¸ veja observaÃ§Ã£o abaixo):
```env
MODEL=OLLAMA
OPENAI_API_KEY=not-needed
```

#### 3. Inicie os containers
```bash
docker compose up -d
```

#### 4. (Se usar Ollama) Baixe o modelo
```bash
docker compose exec ollama ollama pull mistral
```

#### 5. Acesse a aplicaÃ§Ã£o
- **DocumentaÃ§Ã£o**: http://localhost:8000/docs
- **API**: http://localhost:8000

#### âš ï¸ IMPORTANTE: Sobre o uso do Ollama com Docker Compose

**O Ollama no Docker Compose Ã© MUITO LENTO** devido Ã s limitaÃ§Ãµes de recursos do Docker. O processamento pode levar **4-5 minutos ou mais** por requisiÃ§Ã£o. 

**RecomendaÃ§Ãµes:**

1. **MELHOR OPÃ‡ÃƒO**: Use OpenAI GPT com Docker Compose - funciona normalmente e responde rÃ¡pido
2. **ALTERNATIVA**: Se quiser usar Ollama, rode-o **localmente** (fora do Docker) e use a execuÃ§Ã£o local da aplicaÃ§Ã£o com UV
3. **NÃƒO RECOMENDADO**: Ollama dentro do Docker Compose (a menos que vocÃª tenha muito tempo e paciÃªncia)

Se mesmo assim quiser usar Ollama no Docker, aumente o timeout no Postman/cliente HTTP para pelo menos 10 minutos.

## ğŸ“– Uso da API

### Criar um resumo
```bash
POST http://localhost:8000/summary/
Content-Type: application/json

{
  "url": "https://pt.wikipedia.org/wiki/Python_(linguagem_de_programaÃ§Ã£o)",
  "word_count": 50
}
```

### Buscar resumo existente
```bash
GET http://localhost:8000/summary/Python_(linguagem_de_programaÃ§Ã£o)
```

### Exemplos com cURL

**Criar resumo:**
```bash
curl -X POST "http://localhost:8000/summary/" \
  -H "Content-Type: application/json" \
  -d '{
    "url": "https://pt.wikipedia.org/wiki/Python",
    "word_count": 100
  }'
```

**Buscar resumo:**
```bash
curl "http://localhost:8000/summary/Python"
```

## ğŸ§ª Testes

Os testes unitÃ¡rios cobrem 100% dos services (scrapper e summarizer).

### Executar testes localmente
```bash
uv run pytest
```

### Executar testes com coverage
```bash
uv run pytest --cov=app/services --cov-report=term-missing
```

## ğŸ’¡ DecisÃµes de Projeto

### Controle de Palavras
O controle do nÃºmero de palavras no resumo Ã© feito de forma simples, usando o parÃ¢metro `word_count` como uma aproximaÃ§Ã£o do nÃºmero de tokens. **Para um ambiente de produÃ§Ã£o**, seria necessÃ¡rio:
- Implementar contagem precisa de tokens usando o tokenizer especÃ­fico do modelo
- Adicionar pÃ³s-processamento para garantir o limite exato de palavras
- Implementar validaÃ§Ã£o mais robusta do output

**LimitaÃ§Ã£o conhecida**: LLMs nÃ£o sÃ£o eficientes em "contar" coisas. Eles podem gerar textos com mais ou menos palavras do que o solicitado. Uma soluÃ§Ã£o mais robusta envolveria pÃ³s-processamento ou tÃ©cnicas de prompting mais avanÃ§adas.

### Escolha do Modelo
O projeto usa **Mistral 7B** como modelo padrÃ£o do Ollama por:
- Rodar eficientemente em CPU
- NÃ£o requerer GPU ou recursos de hardware especÃ­ficos
- Ser gratuito e open-source
- Ter bom desempenho em tarefas de sumarizaÃ§Ã£o

Alternativamente, pode-se usar **OpenAI GPT-4** para:
- Melhor qualidade de resumos
- Respostas mais rÃ¡pidas
- Melhor aderÃªncia ao limite de palavras

### Performance e Docker
O Ollama tem **performance significativamente reduzida** quando executado dentro do Docker devido Ã s limitaÃ§Ãµes de recursos. Tempos de resposta podem variar de 4-10 minutos dependendo do tamanho do artigo.

**RecomendaÃ§Ã£o para produÃ§Ã£o**: Use OpenAI API ou configure o Ollama em uma mÃ¡quina dedicada com recursos adequados.

### Uso de IA no Desenvolvimento
Este projeto utilizou assistÃªncia de IA (GitHub Copilot) em:
- âœ… GeraÃ§Ã£o de testes unitÃ¡rios (revisados e validados)
- âœ… DocumentaÃ§Ã£o (README, docstrings)
- âœ… ResoluÃ§Ã£o de problemas de configuraÃ§Ã£o do Docker Compose
- âœ… ResoluÃ§Ã£o de problemas de conexÃ£o utilizando o ORM

**TODO O CÃ“DIGO GERADO POR IA FOI:**
- ğŸ“– Lido e compreendido completamente
- âœï¸ Revisado e adaptado Ã s necessidades do projeto
- ğŸ§ª Testado e validado
- ğŸ¯ Otimizado para nÃ£o conter cÃ³digo desnecessÃ¡rio

A IA foi usada como ferramenta de **aceleraÃ§Ã£o de desenvolvimento**, especialmente para tarefas repetitivas, mas **todas as decisÃµes arquiteturais e lÃ³gica de negÃ³cio foram feitas manualmente**.

## ğŸ“ Estrutura do Projeto

```
.
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                 # Entry point da aplicaÃ§Ã£o
â”‚   â”œâ”€â”€ settings.py             # ConfiguraÃ§Ãµes e variÃ¡veis de ambiente
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â””â”€â”€ connection.py       # ConfiguraÃ§Ã£o do banco de dados
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ summary.py          # Modelo SQLAlchemy
â”‚   â”œâ”€â”€ repositories/
â”‚   â”‚   â””â”€â”€ summary.py          # Camada de acesso a dados
â”‚   â”œâ”€â”€ router/
â”‚   â”‚   â””â”€â”€ router.py           # Rotas da API
â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â””â”€â”€ summary.py          # Schemas Pydantic
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ scrapper.py         # ServiÃ§o de web scraping
â”‚       â””â”€â”€ summarizer.py       # ServiÃ§o de sumarizaÃ§Ã£o com IA
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_scrapper.py        # Testes do scrapper
â”‚   â””â”€â”€ test_summarizer.py      # Testes do summarizer
â”œâ”€â”€ docker-compose.yml          # OrquestraÃ§Ã£o de containers
â”œâ”€â”€ Dockerfile                  # Imagem da aplicaÃ§Ã£o
â”œâ”€â”€ pyproject.toml              # DependÃªncias e configuraÃ§Ã£o do projeto
â”œâ”€â”€ .env.example                # Exemplo de variÃ¡veis de ambiente
â””â”€â”€ README.md                   # Este arquivo
```
